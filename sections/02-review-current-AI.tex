
\section{Review of current AI mathematics}

In order to judge whether our new framework is valuable or not, it is necessary to know what has been done within "AI mathematics" in the past.

A key question is whether a new framework is really needed or whether incremental progress will eventually take us to real AI mathematics anyway.

Examples of current AI mathematics:

\begin{itemize}
\item The machine-generated Springer book on Lithium-Ion batteries.
\item Apps for school use (photo app, Kikora, maybe Knewton?). Do a proper search and list.
\item A program that can take the entrance exam to University of Tokyo?
\item Various examples from CICM and AITP talks (check the lists and add here)
\item Zeilberger
\item Our identity explorer for multiplicative functions
\item AlphaGo and AlphaZero?
\item Xena
\item Tegmark et al on arXiv
\end{itemize}

A quote from Buzzard and the Xena project: "Computers are now capable of understanding and doing undergraduate level mathematics. In my mind this is a huge deal. They currently donâ€™t do it very well. But they understand it extremely well. And I believe that it is only a matter of time before they start doing it very well. As a benchmark (or challenge), I would be interested in when we will able to get a computer program to pass the end of year exam for my first year undergraduate course. "

An example from Lean:
\url{https://github.com/leanprover-community/lean-perfectoid-spaces}
